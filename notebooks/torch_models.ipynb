{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "from dataset import get_loader, split_datasets, pre_process_data\n",
    "import pandas as pd\n",
    "import glob\n",
    "from loss import calculate_bce\n",
    "from train import train_script\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from train import train_script\n",
    "from model import VGG16\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from metrics import calculate_precision, calculate_recall, calculate_cf\n",
    "from PIL import Image\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_datasets(pre_process_data('../../dog_cats_data/train/'), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 20250\n",
      "Val set: 2250\n",
      "Test set: 2500\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set: {len(train)}')\n",
    "print(f'Val set: {len(val)}')\n",
    "print(f'Test set: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loader(train, 32, 512, True, 6)\n",
    "val_loader = get_loader(val, 32, 512, True, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated_model = models.vgg16(pretrained=False)\n",
    "# updated_model.classifier[6] = nn.Linear(4096, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_script(model, train_loader, val_loader, epochs, device):\n",
    "#     dataloaders = {\n",
    "#         'train': train_loader,\n",
    "#         'val': val_loader\n",
    "#     }\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "#     model = model.to(device)\n",
    "#     for epoch in range(epochs):\n",
    "#         train_loss, val_loss = 0.0, 0.0\n",
    "#         train_prec, val_prec = 0.0, 0.0\n",
    "#         train_rec, val_rec = 0.0, 0.0\n",
    "#         train_tp, train_fp, train_fn, train_tn = 0.0, 0.0, 0.0, 0.0\n",
    "#         val_tp, val_fp, val_fn, val_tn = 0.0, 0.0, 0.0, 0.0\n",
    "#         for phase in ['train', 'val']:\n",
    "#             if phase == 'train':\n",
    "#                 model.train()\n",
    "#             else:\n",
    "#                 model.eval()\n",
    "#             running_loss, running_prec, running_rec = 0.0, 0.0, 0.0\n",
    "#             running_tp, running_fp, running_fn, running_tn = 0.0, 0.0, 0.0, 0.0\n",
    "#             with tqdm(dataloaders[phase], unit=\"batch\") as tepoch:\n",
    "#                 for img, labels in tepoch:\n",
    "#                     img, labels = img.to(device), labels.to(device)\n",
    "#                     optimizer.zero_grad()\n",
    "#                     with torch.set_grad_enabled(phase == 'train'):\n",
    "#                         outputs = model(img)\n",
    "#                         loss = calculate_bce(outputs, labels)\n",
    "#                         precision = calculate_precision(outputs, labels)\n",
    "#                         recall = calculate_recall(outputs, labels)\n",
    "#                         tp, fn, fp, tn = calculate_cf(outputs, labels)\n",
    "#                         if phase == 'train':\n",
    "#                             loss.backward()\n",
    "#                             optimizer.step()\n",
    "#                     running_loss += loss.item()\n",
    "#                     running_prec += precision.item()\n",
    "#                     running_rec += recall.item()\n",
    "#                     running_tp += tp.item()\n",
    "#                     running_fn += fn.item()\n",
    "#                     running_fp += fp.item()\n",
    "#                     running_tn += tn.item()\n",
    "#                     tepoch.set_postfix(loss = loss.item(), precision = precision.item(), recall = recall.item(), tp = tp.item(), fn = fn.item(), fp = fp.item(), tn = tn.item())\n",
    "#             if phase == 'train':\n",
    "#                 train_loss = running_loss / len(dataloaders[phase])\n",
    "#                 train_prec = running_prec / len(dataloaders[phase])\n",
    "#                 train_rec = running_rec / len(dataloaders[phase])\n",
    "#                 train_tp = running_tp \n",
    "#                 train_fn = running_fn \n",
    "#                 train_fp = running_fp \n",
    "#                 train_tn = running_tn \n",
    "#                 print(f'Train loss: {train_loss}')\n",
    "#                 print(f'Train prec: {train_prec}')\n",
    "#                 print(f'Train rec: {train_rec}')\n",
    "#                 print(f'Train tp: {train_tp}')\n",
    "#                 print(f'Train fn: {train_fn}')\n",
    "#                 print(f'Train fp: {train_fp}')\n",
    "#                 print(f'Train tn: {train_tn}')\n",
    "#             else:\n",
    "#                 val_loss = running_loss / len(dataloaders[phase])\n",
    "#                 val_prec = running_prec / len(dataloaders[phase])\n",
    "#                 val_rec = running_rec / len(dataloaders[phase])\n",
    "#                 val_tp = running_tp \n",
    "#                 val_fn = running_fn \n",
    "#                 val_fp = running_fp \n",
    "#                 val_tn = running_tn \n",
    "#                 print(f'Val loss: {val_loss}')\n",
    "#                 print(f'Val prec: {val_prec}')\n",
    "#                 print(f'Val rec: {val_rec}')\n",
    "#                 print(f'Val tp: {val_tp}')\n",
    "#                 print(f'Val fn: {val_fn}')\n",
    "#                 print(f'Val fp: {val_fp}')\n",
    "#                 print(f'Val tn: {val_tn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.vgg16(pretrained=False)\n",
    "# model.classifier[6] = nn.Linear(4096, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myashchks87\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/paperspace/Documents/dogs_cats/notebooks/wandb/run-20231221_083520-3cfq8prx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/yashchks87/dog_cats/runs/3cfq8prx\" target=\"_blank\">expert-breeze-5</a></strong> to <a href=\"https://wandb.ai/yashchks87/dog_cats\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:27<00:00,  1.44batch/s, fn=30, fp=108, loss=0.69, precision=0.493, recall=0.778, tn=39, tp=105]   \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.62batch/s, fn=17, fp=84, loss=0.689, precision=0.451, recall=0.802, tn=32, tp=69]  \n",
      "100%|██████████| 40/40 [00:27<00:00,  1.47batch/s, fn=29, fp=95, loss=0.685, precision=0.543, recall=0.796, tn=45, tp=113]   \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.61batch/s, fn=21, fp=71, loss=0.683, precision=0.517, recall=0.784, tn=34, tp=76]  \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.51batch/s, fn=31, fp=96, loss=0.682, precision=0.527, recall=0.775, tn=48, tp=107] \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.61batch/s, fn=12, fp=69, loss=0.681, precision=0.606, recall=0.898, tn=15, tp=106] \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.49batch/s, fn=49, fp=61, loss=0.649, precision=0.588, recall=0.64, tn=85, tp=87]    \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.65batch/s, fn=2, fp=81, loss=0.68, precision=0.571, recall=0.982, tn=11, tp=108]   \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.49batch/s, fn=51, fp=49, loss=0.641, precision=0.647, recall=0.638, tn=92, tp=90]   \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.64batch/s, fn=23, fp=56, loss=0.638, precision=0.597, recall=0.783, tn=40, tp=83]   \n",
      "100%|██████████| 40/40 [00:27<00:00,  1.44batch/s, fn=49, fp=32, loss=0.563, precision=0.77, recall=0.686, tn=94, tp=107]   \n",
      "100%|██████████| 5/5 [00:02<00:00,  1.67batch/s, fn=28, fp=25, loss=0.534, precision=0.737, recall=0.714, tn=79, tp=70]  \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.52batch/s, fn=28, fp=40, loss=0.51, precision=0.716, recall=0.783, tn=113, tp=101] \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.63batch/s, fn=0, fp=108, loss=1.32, precision=0.463, recall=1, tn=1, tp=93]   \n",
      "100%|██████████| 40/40 [00:28<00:00,  1.42batch/s, fn=33, fp=42, loss=0.506, precision=0.71, recall=0.757, tn=104, tp=103] \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.58batch/s, fn=39, fp=14, loss=0.515, precision=0.811, recall=0.606, tn=89, tp=60]   \n",
      "100%|██████████| 40/40 [00:28<00:00,  1.42batch/s, fn=23, fp=45, loss=0.502, precision=0.712, recall=0.828, tn=103, tp=111]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.64batch/s, fn=77, fp=2, loss=0.718, precision=0.913, recall=0.214, tn=102, tp=21] \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.49batch/s, fn=18, fp=25, loss=0.363, precision=0.82, recall=0.864, tn=125, tp=114] \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.63batch/s, fn=28, fp=15, loss=0.392, precision=0.83, recall=0.723, tn=86, tp=73]   \n",
      "100%|██████████| 40/40 [00:27<00:00,  1.48batch/s, fn=28, fp=25, loss=0.4, precision=0.826, recall=0.81, tn=110, tp=119]   \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.65batch/s, fn=15, fp=31, loss=0.448, precision=0.756, recall=0.865, tn=60, tp=96]  \n",
      "100%|██████████| 40/40 [00:27<00:00,  1.47batch/s, fn=26, fp=20, loss=0.338, precision=0.852, recall=0.816, tn=121, tp=115]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.61batch/s, fn=3, fp=44, loss=0.479, precision=0.676, recall=0.968, tn=63, tp=92]    \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.50batch/s, fn=15, fp=26, loss=0.346, precision=0.819, recall=0.887, tn=123, tp=118]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.56batch/s, fn=53, fp=0, loss=0.492, precision=1, recall=0.495, tn=97, tp=52]       \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.48batch/s, fn=13, fp=15, loss=0.256, precision=0.886, recall=0.9, tn=137, tp=117]  \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.61batch/s, fn=19, fp=9, loss=0.343, precision=0.898, recall=0.806, tn=95, tp=79]   \n",
      "100%|██████████| 40/40 [00:27<00:00,  1.46batch/s, fn=17, fp=24, loss=0.289, precision=0.84, recall=0.881, tn=115, tp=126] \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.65batch/s, fn=11, fp=26, loss=0.419, precision=0.755, recall=0.879, tn=85, tp=80]  \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.50batch/s, fn=11, fp=9, loss=0.203, precision=0.934, recall=0.921, tn=134, tp=128] \n",
      "100%|██████████| 5/5 [00:04<00:00,  1.14batch/s, fn=11, fp=20, loss=0.327, precision=0.823, recall=0.894, tn=78, tp=93]  \n",
      "100%|██████████| 40/40 [00:27<00:00,  1.44batch/s, fn=13, fp=11, loss=0.233, precision=0.922, recall=0.909, tn=128, tp=130]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.60batch/s, fn=53, fp=3, loss=0.503, precision=0.94, recall=0.47, tn=99, tp=47]     \n",
      "100%|██████████| 40/40 [00:27<00:00,  1.46batch/s, fn=3, fp=10, loss=0.121, precision=0.932, recall=0.979, tn=132, tp=137] \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.61batch/s, fn=32, fp=8, loss=0.456, precision=0.892, recall=0.673, tn=96, tp=66]   \n",
      "100%|██████████| 40/40 [00:27<00:00,  1.48batch/s, fn=12, fp=8, loss=0.187, precision=0.942, recall=0.915, tn=133, tp=129] \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.62batch/s, fn=8, fp=23, loss=0.372, precision=0.793, recall=0.917, tn=83, tp=88]   \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.50batch/s, fn=5, fp=11, loss=0.159, precision=0.927, recall=0.966, tn=126, tp=140] \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.64batch/s, fn=7, fp=18, loss=0.325, precision=0.816, recall=0.92, tn=97, tp=80]    \n",
      "100%|██████████| 40/40 [00:27<00:00,  1.46batch/s, fn=10, fp=6, loss=0.128, precision=0.959, recall=0.934, tn=124, tp=142]  \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.59batch/s, fn=8, fp=29, loss=0.538, precision=0.78, recall=0.928, tn=62, tp=103]   \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.49batch/s, fn=6, fp=7, loss=0.0799, precision=0.952, recall=0.959, tn=130, tp=139] \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.61batch/s, fn=9, fp=11, loss=0.313, precision=0.883, recall=0.902, tn=99, tp=83]   \n",
      "100%|██████████| 40/40 [00:27<00:00,  1.46batch/s, fn=13, fp=4, loss=0.135, precision=0.971, recall=0.913, tn=129, tp=136] \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.60batch/s, fn=11, fp=13, loss=0.25, precision=0.882, recall=0.898, tn=81, tp=97]   \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.49batch/s, fn=3, fp=5, loss=0.0683, precision=0.967, recall=0.98, tn=127, tp=147]   \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.62batch/s, fn=26, fp=7, loss=0.387, precision=0.916, recall=0.745, tn=93, tp=76]   \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.50batch/s, fn=2, fp=2, loss=0.0413, precision=0.986, recall=0.986, tn=139, tp=139] \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.66batch/s, fn=13, fp=15, loss=0.399, precision=0.856, recall=0.873, tn=85, tp=89]  \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.53batch/s, fn=6, fp=4, loss=0.0651, precision=0.972, recall=0.958, tn=134, tp=138] \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.62batch/s, fn=21, fp=4, loss=0.566, precision=0.953, recall=0.794, tn=96, tp=81]   \n",
      "100%|██████████| 40/40 [00:27<00:00,  1.48batch/s, fn=4, fp=0, loss=0.0515, precision=1, recall=0.973, tn=134, tp=144]     \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.64batch/s, fn=10, fp=11, loss=0.311, precision=0.891, recall=0.9, tn=91, tp=90]    \n",
      "100%|██████████| 40/40 [00:28<00:00,  1.43batch/s, fn=1, fp=1, loss=0.0176, precision=0.993, recall=0.993, tn=141, tp=139]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.64batch/s, fn=13, fp=20, loss=0.847, precision=0.831, recall=0.883, tn=71, tp=98]  \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.48batch/s, fn=2, fp=1, loss=0.0251, precision=0.993, recall=0.986, tn=134, tp=145]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.61batch/s, fn=24, fp=12, loss=0.679, precision=0.86, recall=0.755, tn=92, tp=74]   \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.51batch/s, fn=1, fp=0, loss=0.0163, precision=1, recall=0.993, tn=138, tp=143]     \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.61batch/s, fn=17, fp=11, loss=0.586, precision=0.898, recall=0.851, tn=77, tp=97]  \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.48batch/s, fn=0, fp=5, loss=0.0343, precision=0.968, recall=1, tn=128, tp=149]    \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.56batch/s, fn=15, fp=10, loss=0.432, precision=0.895, recall=0.85, tn=92, tp=85]   \n",
      "100%|██████████| 40/40 [00:27<00:00,  1.45batch/s, fn=1, fp=2, loss=0.0286, precision=0.987, recall=0.993, tn=130, tp=149] \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.62batch/s, fn=10, fp=21, loss=1.1, precision=0.826, recall=0.909, tn=71, tp=100]   \n",
      "100%|██████████| 40/40 [00:27<00:00,  1.48batch/s, fn=0, fp=4, loss=0.032, precision=0.972, recall=1, tn=139, tp=139]     \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.62batch/s, fn=28, fp=7, loss=0.711, precision=0.916, recall=0.731, tn=91, tp=76]   \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.49batch/s, fn=0, fp=0, loss=0.00198, precision=1, recall=1, tn=145, tp=137]        \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.61batch/s, fn=24, fp=7, loss=0.469, precision=0.915, recall=0.758, tn=96, tp=75]   \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.49batch/s, fn=1, fp=2, loss=0.0248, precision=0.986, recall=0.993, tn=138, tp=141] \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.64batch/s, fn=43, fp=1, loss=1.26, precision=0.983, recall=0.574, tn=100, tp=58]   \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.52batch/s, fn=1, fp=0, loss=0.0149, precision=1, recall=0.993, tn=130, tp=151]     \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.60batch/s, fn=21, fp=15, loss=0.689, precision=0.845, recall=0.796, tn=84, tp=82]  \n",
      "100%|██████████| 40/40 [00:28<00:00,  1.40batch/s, fn=4, fp=0, loss=0.027, precision=1, recall=0.972, tn=140, tp=138]      \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.65batch/s, fn=8, fp=8, loss=0.314, precision=0.919, recall=0.919, tn=95, tp=91]   \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.52batch/s, fn=2, fp=1, loss=0.0544, precision=0.993, recall=0.986, tn=136, tp=143] \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.65batch/s, fn=35, fp=2, loss=0.903, precision=0.973, recall=0.67, tn=94, tp=71]  \n",
      "100%|██████████| 40/40 [00:29<00:00,  1.34batch/s, fn=0, fp=0, loss=0.0071, precision=1, recall=1, tn=147, tp=135]        \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.67batch/s, fn=16, fp=12, loss=0.466, precision=0.879, recall=0.845, tn=87, tp=87]  \n",
      "100%|██████████| 40/40 [00:27<00:00,  1.45batch/s, fn=0, fp=0, loss=0.00553, precision=1, recall=1, tn=141, tp=141]       \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.63batch/s, fn=4, fp=26, loss=0.862, precision=0.792, recall=0.961, tn=73, tp=99]   \n",
      "100%|██████████| 40/40 [00:27<00:00,  1.47batch/s, fn=1, fp=1, loss=0.019, precision=0.992, recall=0.992, tn=150, tp=130] \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.62batch/s, fn=3, fp=25, loss=0.712, precision=0.826, recall=0.975, tn=55, tp=119] \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.50batch/s, fn=4, fp=0, loss=0.017, precision=1, recall=0.974, tn=131, tp=147]      \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.61batch/s, fn=34, fp=4, loss=1.01, precision=0.938, recall=0.638, tn=104, tp=60]   \n",
      "100%|██████████| 40/40 [00:27<00:00,  1.48batch/s, fn=1, fp=0, loss=0.0208, precision=1, recall=0.993, tn=129, tp=152]     \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.62batch/s, fn=8, fp=18, loss=0.557, precision=0.835, recall=0.919, tn=85, tp=91]   \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.50batch/s, fn=0, fp=1, loss=0.00671, precision=0.993, recall=1, tn=142, tp=139]    \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.63batch/s, fn=14, fp=16, loss=1.26, precision=0.846, recall=0.863, tn=84, tp=88]   \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.49batch/s, fn=2, fp=0, loss=0.0106, precision=1, recall=0.985, tn=150, tp=130]    \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.65batch/s, fn=4, fp=22, loss=1.63, precision=0.815, recall=0.96, tn=79, tp=97]     \n",
      "100%|██████████| 40/40 [00:29<00:00,  1.34batch/s, fn=1, fp=0, loss=0.0138, precision=1, recall=0.993, tn=144, tp=137]     \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.59batch/s, fn=7, fp=18, loss=0.663, precision=0.83, recall=0.926, tn=89, tp=88]    \n",
      "100%|██████████| 40/40 [00:28<00:00,  1.40batch/s, fn=0, fp=0, loss=0.00492, precision=1, recall=1, tn=142, tp=140]        \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.64batch/s, fn=15, fp=16, loss=0.724, precision=0.855, recall=0.862, tn=77, tp=94]  \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.48batch/s, fn=0, fp=0, loss=0.00192, precision=1, recall=1, tn=135, tp=147]       \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.63batch/s, fn=14, fp=12, loss=1.55, precision=0.886, recall=0.869, tn=83, tp=93]   \n",
      "100%|██████████| 40/40 [00:27<00:00,  1.44batch/s, fn=0, fp=0, loss=0.00196, precision=1, recall=1, tn=142, tp=140]        \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.64batch/s, fn=8, fp=14, loss=0.577, precision=0.873, recall=0.923, tn=84, tp=96]   \n",
      "100%|██████████| 40/40 [00:26<00:00,  1.49batch/s, fn=0, fp=4, loss=0.0227, precision=0.972, recall=1, tn=141, tp=137]    \n",
      "100%|██████████| 5/5 [00:03<00:00,  1.49batch/s, fn=19, fp=14, loss=0.965, precision=0.843, recall=0.798, tn=94, tp=75]  \n"
     ]
    }
   ],
   "source": [
    "train_script(VGG16(), train_loader, val_loader, 50, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "base_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
